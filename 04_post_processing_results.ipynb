{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to read out AF3 output, calculate scores and plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio.PDB import MMCIFParser\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Rectangle\n",
    "from collections import Counter\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import zipfile\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 150 # change this for high resolution output\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "def transform_pae_matrix(pae_matrix, pae_cutoff):\n",
    "    # Initialize the transformed matrix with zeros\n",
    "    transformed_pae = np.zeros_like(pae_matrix)\n",
    "\n",
    "    # Apply transformation: pae = 0 -> score = 1, pae = cutoff -> score = 0, above cutoff -> score = 0\n",
    "    # Linearly scale values between 0 and cutoff to fall between 1 and 0\n",
    "    within_cutoff = pae_matrix < pae_cutoff\n",
    "    transformed_pae[within_cutoff] = 1 - (pae_matrix[within_cutoff] / pae_cutoff)\n",
    "    \n",
    "    return transformed_pae\n",
    "\n",
    "def calculate_mean_lis(transformed_pae, subunit_number):\n",
    "    # Calculate the cumulative sum of protein lengths to get the end indices of the submatrices\n",
    "    cum_lengths = np.cumsum(subunit_number)\n",
    "    \n",
    "    # Add a zero at the beginning of the cumulative lengths to get the start indices\n",
    "    start_indices = np.concatenate(([0], cum_lengths[:-1]))\n",
    "    \n",
    "    # Initialize an empty matrix to store the mean LIS\n",
    "    mean_lis_matrix = np.zeros((len(subunit_number), len(subunit_number)))\n",
    "    \n",
    "    # Iterate over the start and end indices\n",
    "    for i in range(len(subunit_number)):\n",
    "        for j in range(len(subunit_number)):\n",
    "            # Get the start and end indices of the interaction submatrix\n",
    "            start_i, end_i = start_indices[i], cum_lengths[i]\n",
    "            start_j, end_j = start_indices[j], cum_lengths[j]\n",
    "            \n",
    "            # Get the interaction submatrix\n",
    "            submatrix = transformed_pae[start_i:end_i, start_j:end_j]\n",
    "            \n",
    "            # Calculate the mean LIS, considering only non-zero values\n",
    "            mean_lis = submatrix[submatrix > 0].mean()\n",
    "            \n",
    "            # Store the mean LIS in the matrix\n",
    "            mean_lis_matrix[i, j] = mean_lis\n",
    "    \n",
    "    return mean_lis_matrix\n",
    "\n",
    "def calculate_contact_map(cif_file, distance_threshold=8):\n",
    "    def read_cif_lines(cif_path):\n",
    "        with open(cif_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        residue_lines = []\n",
    "        for line in lines:\n",
    "            if line.startswith('ATOM') and ('CB' in line or 'GLY' in line and 'CA' in line):\n",
    "                residue_lines.append(line.strip())  # Store the line if it meets the criteria for ATOM\n",
    "\n",
    "            if line.startswith('ATOM') and 'P   ' in line:\n",
    "                residue_lines.append(line.strip()) # Store the line if it meets the criteria for ATOM\n",
    "\n",
    "            elif line.startswith('HETATM'):\n",
    "                residue_lines.append(line.strip())  # Store all HETATM lines\n",
    "\n",
    "        return residue_lines\n",
    "\n",
    "    def lines_to_dataframe(residue_lines):\n",
    "        # Split lines and create a list of dictionaries for each atom\n",
    "        data = []\n",
    "        for line in residue_lines:\n",
    "            parts = line.split()\n",
    "            # Correctly convert numerical values\n",
    "            for i in range(len(parts)):\n",
    "                try:\n",
    "                    parts[i] = float(parts[i])\n",
    "                except ValueError:\n",
    "                    pass\n",
    "            data.append(parts)\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # Add line number column\n",
    "        df.insert(0, 'residue', range(1, 1 + len(df)))\n",
    "\n",
    "        return df\n",
    "\n",
    "    # Read lines from CIF file\n",
    "    residue_lines = read_cif_lines(cif_file)\n",
    "\n",
    "    # Convert lines to DataFrame\n",
    "    df = lines_to_dataframe(residue_lines)\n",
    "\n",
    "    # Assuming the columns for x, y, z coordinates are at indices 11, 12, 13 after insertion\n",
    "    coordinates = df.iloc[:, 11:14].to_numpy()\n",
    "\n",
    "    distances = squareform(pdist(coordinates))\n",
    "\n",
    "    # Assuming the column for atom names is at index 3 after insertion\n",
    "    has_phosphorus = df.iloc[:, 3].apply(lambda x: 'P' in str(x)).to_numpy()\n",
    "\n",
    "    # Adjust the threshold for phosphorus-containing residues\n",
    "    adjusted_distances = np.where(has_phosphorus[:, np.newaxis] | has_phosphorus[np.newaxis, :], \n",
    "                                  distances - 4, distances)\n",
    "\n",
    "    contact_map = np.where(adjusted_distances < distance_threshold, 1, 0)\n",
    "    return contact_map\n",
    "\n",
    "\n",
    "def generate_json_paths(base_path, number_of_models=5):\n",
    "    \"\"\"\n",
    "    Generates a list of JSON file paths for a given number of models within a specified base path.\n",
    "\n",
    "    Parameters:\n",
    "    - base_path (str): The base directory where the model JSON files are stored.\n",
    "    - number_of_models (int): The number of model JSON files to generate paths for.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of fully qualified paths to the JSON files.\n",
    "    \"\"\"\n",
    "    model_identifier = os.path.basename(base_path)\n",
    "    json_files = [f\"{base_path}/fold_{model_identifier}_full_data_{model}.json\" for model in range(number_of_models)]\n",
    "    return json_files\n",
    "\n",
    "\n",
    "def afm3_plot_average_to_df(af3_jsons, pae_cutoff=12, distance_cutoff=8, result_save = \"True\"):\n",
    "    sum_pae_matrix = None\n",
    "    sum_transformed_pae_matrix = None\n",
    "    sum_mean_lis_matrix = None\n",
    "    sum_contact_lia_map = None\n",
    "    sum_iptm_matrix = None\n",
    "    all_interactions = []\n",
    "\n",
    "    for af3_json in af3_jsons:\n",
    "        json_data = json.load(open(af3_json, 'rb'))\n",
    "        json_confidence = af3_json.replace('full_data', 'summary_confidences')\n",
    "        confidence_data = json.load(open(json_confidence, 'rb'))\n",
    "        token_chain_ids = json_data['token_chain_ids']\n",
    "        chain_residue_counts = Counter(token_chain_ids)\n",
    "        subunit_number = list(chain_residue_counts.values())\n",
    "        pae_matrix = np.array(json_data['pae'])\n",
    "        subunit_sizes = subunit_number\n",
    "        \n",
    "        cif_file = af3_json.replace('_full_data_', '_model_').replace('.json', '.cif')\n",
    "        \n",
    "        transformed_pae_matrix = transform_pae_matrix(pae_matrix, pae_cutoff)\n",
    "        transformed_pae_matrix = np.nan_to_num(transformed_pae_matrix)\n",
    "        lia_map = np.where(transformed_pae_matrix > 0, 1, 0)\n",
    "\n",
    "        mean_lis_matrix = calculate_mean_lis(transformed_pae_matrix, subunit_sizes)\n",
    "        mean_lis_matrix = np.nan_to_num(mean_lis_matrix)\n",
    "\n",
    "        contact_map = calculate_contact_map(cif_file, distance_cutoff)\n",
    "        combined_map = np.where((transformed_pae_matrix > 0) & (contact_map == 1), transformed_pae_matrix, 0)\n",
    "        \n",
    "        mean_clis_matrix = calculate_mean_lis(combined_map, subunit_sizes)\n",
    "        mean_clis_matrix = np.nan_to_num(mean_clis_matrix)\n",
    "\n",
    "        lia_matrix = np.zeros((len(subunit_sizes), len(subunit_sizes)))\n",
    "        lir_matrix = np.zeros((len(subunit_sizes), len(subunit_sizes)))\n",
    "        clia_matrix = np.zeros((len(subunit_sizes), len(subunit_sizes)))\n",
    "        clir_matrix = np.zeros((len(subunit_sizes), len(subunit_sizes)))\n",
    "\n",
    "        for i in range(len(subunit_sizes)):\n",
    "            for j in range(len(subunit_sizes)):\n",
    "                start_i, end_i = sum(subunit_sizes[:i]), sum(subunit_sizes[:i+1])\n",
    "                start_j, end_j = sum(subunit_sizes[:j]), sum(subunit_sizes[:j+1])\n",
    "                \n",
    "                interaction_submatrix = lia_map[start_i:end_i, start_j:end_j]\n",
    "\n",
    "                lia_matrix[i, j] = int(np.count_nonzero(interaction_submatrix))\n",
    "                residues_i = np.unique(np.where(interaction_submatrix > 0)[0]) + start_i\n",
    "                residues_j = np.unique(np.where(interaction_submatrix > 0)[1]) + start_j\n",
    "                lir_matrix[i, j] = int(len(residues_i) + len(residues_j))\n",
    "\n",
    "                combined_submatrix = combined_map[start_i:end_i, start_j:end_j]\n",
    "                clia_matrix[i, j] = int(np.count_nonzero(combined_submatrix))\n",
    "\n",
    "                residues_i = np.unique(np.where(combined_submatrix > 0)[0]) + start_i\n",
    "                residues_j = np.unique(np.where(combined_submatrix > 0)[1]) + start_j\n",
    "                clir_matrix[i, j] = int(len(residues_i) + len(residues_j))\n",
    "\n",
    "        iptm_matrix = confidence_data['chain_pair_iptm']\n",
    "        iptm_matrix = np.array(iptm_matrix, dtype=float)\n",
    "        iptm_matrix = np.nan_to_num(iptm_matrix)\n",
    "\n",
    "        if sum_pae_matrix is None:\n",
    "            sum_pae_matrix = pae_matrix\n",
    "            sum_transformed_pae_matrix = transformed_pae_matrix\n",
    "            sum_mean_lis_matrix = mean_lis_matrix\n",
    "            sum_contact_lia_map = combined_map\n",
    "            sum_iptm_matrix = iptm_matrix\n",
    "        else:\n",
    "            sum_pae_matrix += pae_matrix\n",
    "            sum_transformed_pae_matrix += transformed_pae_matrix\n",
    "            sum_mean_lis_matrix += mean_lis_matrix\n",
    "            sum_contact_lia_map += combined_map\n",
    "            sum_iptm_matrix += iptm_matrix\n",
    "\n",
    "        model_number = re.search(r'full_data_(\\d+)', af3_json).group(1)\n",
    "        folder_name = os.path.basename(os.path.dirname(af3_json))\n",
    "        for i in range(len(subunit_sizes)):\n",
    "            for j in range(len(subunit_sizes)):\n",
    "                interaction = {\n",
    "                    'folder_name': folder_name,\n",
    "                    'model_number': model_number,\n",
    "                    'protein_1': i + 1,\n",
    "                    'protein_2': j + 1,\n",
    "                    'LIS': mean_lis_matrix[i, j],\n",
    "                    'LIA': lia_matrix[i, j],\n",
    "                    'LIR': lir_matrix[i, j],\n",
    "                    'cLIS': mean_clis_matrix[i, j],\n",
    "                    'cLIA': clia_matrix[i, j],\n",
    "                    'cLIR': clir_matrix[i, j],\n",
    "                    'iptm': iptm_matrix[i, j],\n",
    "                }\n",
    "                all_interactions.append(interaction)\n",
    "\n",
    "    avg_pae_matrix = sum_pae_matrix / len(af3_jsons)\n",
    "    avg_transformed_pae_matrix = sum_transformed_pae_matrix / len(af3_jsons)\n",
    "    avg_mean_lis_matrix = sum_mean_lis_matrix / len(af3_jsons)\n",
    "    avg_contact_lia_map = sum_contact_lia_map / len(af3_jsons)\n",
    "    avg_iptm_matrix = sum_iptm_matrix / len(af3_jsons)\n",
    "\n",
    "    avg_pae_matrix = np.nan_to_num(avg_pae_matrix)\n",
    "    avg_transformed_pae_matrix = np.nan_to_num(avg_transformed_pae_matrix)\n",
    "    avg_mean_lis_matrix = np.nan_to_num(avg_mean_lis_matrix)\n",
    "    avg_iptm_matrix = np.nan_to_num(avg_iptm_matrix)\n",
    "\n",
    "    df_interactions = pd.DataFrame(all_interactions)\n",
    "    df_interactions['interaction'] = df_interactions.apply(lambda row: tuple(sorted((row['protein_1'], row['protein_2']))), axis=1)\n",
    "    df_merged = df_interactions.groupby(['folder_name', 'model_number', 'interaction']).mean().reset_index()\n",
    "    df_merged[['protein_1', 'protein_2']] = pd.DataFrame(df_merged['interaction'].tolist(), index=df_merged.index)\n",
    "    df_merged = df_merged.drop(columns=['interaction'])\n",
    "\n",
    "    # Calculate average values for each protein pair and add as new rows\n",
    "    avg_rows = []\n",
    "    interaction_pairs = df_merged.groupby(['protein_1', 'protein_2'])\n",
    "\n",
    "    for (protein_1, protein_2), group in interaction_pairs:\n",
    "        avg_row = {\n",
    "            'folder_name': folder_name,\n",
    "            'model_number': 'average',\n",
    "            'protein_1': protein_1,\n",
    "            'protein_2': protein_2,\n",
    "            'LIS': group['LIS'].mean(),\n",
    "            'LIA': group['LIA'].mean(),\n",
    "            'LIR': group['LIR'].mean(),\n",
    "            'cLIS': group['cLIS'].mean(),\n",
    "            'cLIA': group['cLIA'].mean(),\n",
    "            'cLIR': group['cLIR'].mean(),\n",
    "            'iptm': group['iptm'].mean(),\n",
    "        }\n",
    "        avg_rows.append(avg_row)\n",
    "\n",
    "    df_avg = pd.DataFrame(avg_rows)\n",
    "    df_merged = pd.concat([df_merged, df_avg], ignore_index=True)\n",
    "\n",
    "    df_merged['LIA'] = df_merged['LIA'].astype(int)\n",
    "    df_merged['LIR'] = df_merged['LIR'].astype(int)\n",
    "    df_merged['cLIA'] = df_merged['cLIA'].astype(int)\n",
    "    df_merged['cLIR'] = df_merged['cLIR'].astype(int)\n",
    "\n",
    "    # Save DataFrame to CSV\n",
    "    output_folder = os.path.dirname(af3_jsons[0])\n",
    "    output_path = os.path.join(output_folder, f\"{folder_name}_lis_analysis.csv\")\n",
    "    if result_save == \"True\":\n",
    "        df_merged.to_csv(output_path, index=False)\n",
    "        print(\"Results saved to: \", output_path)\n",
    "        print(f\"{folder_name}_lis_analysis.csv\")\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 150\n",
    "\n",
    "# Function to extract average LIS for protein 1 and 2 from df_interactions\n",
    "def extract_lis_from_df(df_interactions):\n",
    "    row = df_interactions.loc[(df_interactions['model_number'] == '0') &\n",
    "                              (df_interactions['protein_1'] == 1) &\n",
    "                              (df_interactions['protein_2'] == 2)]\n",
    "    if not row.empty:\n",
    "        return row['LIS'].values[0]\n",
    "    return np.nan\n",
    "\n",
    "# Function to compute average iPTM from the _summary_confidences_*.json files\n",
    "def calculate_average_iptm(json_files):\n",
    "    iptm_values = []\n",
    "    for json_file in json_files:\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            iptm_values.append(data.get('iptm', 0))\n",
    "    if iptm_values:\n",
    "        return np.mean(iptm_values)\n",
    "    return np.nan\n",
    "\n",
    "# Function to unzip and delete zip files in the subdirectory\n",
    "def unzip_and_cleanup(dir_path):\n",
    "    for file in os.listdir(dir_path):\n",
    "        file_path = os.path.join(dir_path, file)\n",
    "        if file.endswith(\".zip\") and os.path.isfile(file_path):\n",
    "            # Create a directory with the same name as the zip file (without .zip)\n",
    "            extract_dir = os.path.join(dir_path, file[:-4])  # Remove '.zip' extension\n",
    "            os.makedirs(extract_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "            # Extract all contents into the newly created directory\n",
    "            with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(extract_dir)  # Extract contents into the new directory\n",
    "\n",
    "            os.remove(file_path)  # Delete the zip file after extraction\n",
    "\n",
    "# Function to process a given subdirectory\n",
    "def process_subdirectory(subdir_path, identity, pae_cutoff=12, distance_cutoff=8):    \n",
    "    json_files = generate_json_paths(subdir_path, number_of_models=5)\n",
    "    df_interactions = afm3_plot_average_to_df(json_files, pae_cutoff=pae_cutoff, distance_cutoff=distance_cutoff, result_save=False)\n",
    "    \n",
    "    lis_value = extract_lis_from_df(df_interactions)\n",
    "    summary_json_files = [os.path.join(subdir_path, f) for f in os.listdir(subdir_path) if f.endswith(\".json\") and \"_summary_confidences_\" in f]\n",
    "    avg_iptm = calculate_average_iptm(summary_json_files)\n",
    "\n",
    "    protein_name_parts = os.path.basename(subdir_path).split(\"_\")\n",
    "    protein1 = protein_name_parts[-2]\n",
    "    protein2 = protein_name_parts[-1]\n",
    "\n",
    "    new_row = pd.DataFrame([{\n",
    "        'P2P': f\"{protein1}-{protein2}\",\n",
    "        'protein1': protein1,\n",
    "        'protein2': protein2,\n",
    "        'iPTM': avg_iptm,\n",
    "        'LIS': lis_value,\n",
    "        'identity': identity\n",
    "    }])\n",
    "    return new_row\n",
    "\n",
    "# Main function to process the dataset and create the results dataframe\n",
    "def process_dataset(data_dir, pae_cutoff=12, distance_cutoff=8):\n",
    "    results_df = pd.DataFrame(columns=['P2P', 'protein1', 'protein2', 'iPTM', 'LIS', 'identity'])\n",
    "\n",
    "    for child_dir in os.listdir(data_dir):\n",
    "        child_dir_path = os.path.join(data_dir, child_dir)\n",
    "        \n",
    "        if os.path.isdir(child_dir_path):\n",
    "            identity = \"\"\n",
    "            if child_dir == 'negative_controls' or child_dir == 'Negative_controls':\n",
    "                identity = \"negative control\"\n",
    "            elif child_dir == 'positive_controls' or child_dir == 'Positive_controls':\n",
    "                identity = \"positive control\"\n",
    "            else:\n",
    "                identity = child_dir  # Assuming other directories follow {gene_name}_genes format\n",
    "            \n",
    "            unzip_and_cleanup(child_dir_path)\n",
    "\n",
    "            for subdir in os.listdir(child_dir_path):\n",
    "                subdir_path = os.path.join(child_dir_path, subdir)\n",
    "                if os.path.isdir(subdir_path):\n",
    "                    new_row = process_subdirectory(subdir_path, identity, pae_cutoff, distance_cutoff)\n",
    "                    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "# Plotting function\n",
    "def plot_results(results_df, highlight_labels, general_label, DATA_DIR):\n",
    "    neg_controls = results_df[results_df['identity'] == 'negative control']\n",
    "    pos_controls = results_df[results_df['identity'] == 'positive control']\n",
    "    \n",
    "    # Check if general_label is a list and filter accordingly\n",
    "    if isinstance(general_label, list):\n",
    "        general_label_data = results_df[results_df['identity'].isin(general_label)]\n",
    "        general_palette = sns.color_palette(\"cool\", len(general_label))  # Palette for general_label points\n",
    "    else:\n",
    "        general_label_data = results_df[results_df['identity'] == general_label]\n",
    "        general_palette = [\"blue\"]  # Single color if only one label\n",
    "\n",
    "    # Create a color palette for the highlighted points\n",
    "    highlight_palette = sns.color_palette(\"husl\", len(highlight_labels))\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    \n",
    "    # Plot the points for general_label(s)\n",
    "    if not general_label_data.empty:\n",
    "        for idx, label in enumerate(general_label if isinstance(general_label, list) else [general_label]):\n",
    "            label_data = general_label_data[general_label_data['identity'] == label]\n",
    "            plt.scatter(label_data['iPTM'], label_data['LIS'], color=general_palette[idx], \n",
    "                        label=label, s=50, edgecolor='black')\n",
    "    \n",
    "    if not neg_controls.empty:\n",
    "        plt.scatter(neg_controls['iPTM'], neg_controls['LIS'], color='red', label='negative control')\n",
    "    \n",
    "    if not pos_controls.empty:\n",
    "        plt.scatter(pos_controls['iPTM'], pos_controls['LIS'], color='green', label='positive control')\n",
    "    \n",
    "    # Plot highlighted points for each label in the list\n",
    "    for i, highlight_label in enumerate(highlight_labels):\n",
    "        highlighted_points = results_df[results_df['P2P'] == highlight_label]\n",
    "        if not highlighted_points.empty:\n",
    "            plt.scatter(highlighted_points['iPTM'], highlighted_points['LIS'], \n",
    "                        color=highlight_palette[i], label=f'highlight: {highlight_label}', s=50, edgecolor='black')\n",
    "\n",
    "    plt.axvline(0, c=\"black\")\n",
    "    plt.axhline(0, c=\"black\")\n",
    "    plt.title(f'Protein-Protein Interaction Scores from AlphaFold3')\n",
    "    plt.xlabel('iPTM')\n",
    "    plt.ylabel('LIS')\n",
    "    plt.legend()\n",
    "    plt.xlim(0, )\n",
    "    plt.ylim(0, )\n",
    "    plt.savefig(f'{DATA_DIR}LIS-to-iPTM-plot.svg', format='svg', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot AlphaFold3 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"af3_outputs/\"\n",
    "RES_DIR = \"results/\"\n",
    "pae_cutoff = 12\n",
    "distance_cutoff = 8\n",
    "\n",
    "# Run the full dataset processing\n",
    "results_df = process_dataset(DATA_DIR, pae_cutoff, distance_cutoff)\n",
    "\n",
    "# Save the results\n",
    "results_df.to_csv(f'{RES_DIR}final_results.csv', index=False)\n",
    "\n",
    "# Plot the results\n",
    "plot_results(results_df, [], 'tested P2P-Int', RES_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
