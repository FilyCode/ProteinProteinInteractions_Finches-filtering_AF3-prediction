{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking and defining caspase enzymes in RPG...\n",
      "Existing RPG enzymes found: set()\n",
      "Attempting to define new enzyme: 'Caspase-2_consens' with rule '(V)(D)(V)(A)(D,)'...\n",
      "Enzyme 'Caspase-2_consens' already exists (as reported by RPG's stderr). Skipping definition.\n",
      "Attempting to define new enzyme: 'Caspase-3_consens' with rule '(D)(E)(V)(D,)'...\n",
      "Successfully defined 'Caspase-3_consens'.\n",
      "Attempting to define new enzyme: 'Caspase-6_consens' with rule '(V)(E)(H)(D,)'...\n",
      "Enzyme 'Caspase-6_consens' already exists (as reported by RPG's stderr). Skipping definition.\n",
      "Attempting to define new enzyme: 'Caspase-7_consens' with rule '(D)(E)(V)(D,)'...\n",
      "Successfully defined 'Caspase-7_consens'.\n",
      "Attempting to define new enzyme: 'Caspase-8_consens' with rule '(I)(E)(T)(D,)'...\n",
      "Enzyme 'Caspase-8_consens' already exists (as reported by RPG's stderr). Skipping definition.\n",
      "Attempting to define new enzyme: 'Caspase-9_consens' with rule '(L)(E)(H)(D,)'...\n",
      "Enzyme 'Caspase-9_consens' already exists (as reported by RPG's stderr). Skipping definition.\n",
      "Attempting to define new enzyme: 'Caspase-10_consens' with rule '(A)(E)(V)(D,)'...\n",
      "Enzyme 'Caspase-10_consens' already exists (as reported by RPG's stderr). Skipping definition.\n",
      "Parsing FASTA file: data/all_virus_proteins.fasta\n",
      "Found 1522 sequences in FASTA.\n",
      "Loading Excel file: data/RITA_and_ABT_pos_selection_screens.xlsx, sheet: RITA\n",
      "Original rows in 'RITA': 32721\n",
      "Filtered rows (type in [VP, VT] and sig=Yes): 498\n",
      "Warning: 30 rows from Excel could not be matched to FASTA sequences by NCBI_id and were dropped.\n",
      "Unique proteins (324) written to temporary FASTA: /scratch/847344.1.mnemosyne-pub/tmpgt34veqs/unique_proteins_for_rpg.fasta\n",
      "Initiating RPG digestion for all relevant caspases on unique proteins...\n",
      "Processing unique proteins for caspase cleavage sites...\n",
      "  Running RPG for 'Caspase-2_consens'...\n",
      "  Running RPG for 'Caspase-3_consens'...\n",
      "  Running RPG for 'Caspase-6_consens'...\n",
      "  Running RPG for 'Caspase-7_consens'...\n",
      "  Running RPG for 'Caspase-8_consens'...\n",
      "  Running RPG for 'Caspase-9_consens'...\n",
      "  Running RPG for 'Caspase-10_consens'...\n",
      "Finished processing unique proteins for caspase cleavage sites.\n",
      "RPG digestion and result collection complete.\n",
      "Analyzing tiles and generating final output rows...\n",
      "\n",
      "Pipeline complete. Results saved to results/RITA_virus_caspase_analysis.csv\n",
      "Cleaned up temporary directory: /scratch/847344.1.mnemosyne-pub/tmpgt34veqs\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "import tempfile\n",
    "from Bio import SeqIO # Using Biopython for robust FASTA parsing\n",
    "import numpy as np # For numerical operations, especially distances\n",
    "\n",
    "# Re-using functions from the previous script\n",
    "def define_caspase_enzymes(caspase_rules):\n",
    "    \"\"\"\n",
    "    Programmatically defines custom caspase enzymes in RPG if they don't exist,\n",
    "    using the correct rule syntax. Handles \"This name exist\" gracefully.\n",
    "    Returns a set of all caspase enzyme names that are now available in RPG.\n",
    "    \"\"\"\n",
    "    print(\"Checking and defining caspase enzymes in RPG...\")\n",
    "    \n",
    "    all_available_caspase_names = set()\n",
    "\n",
    "    try:\n",
    "        # Using '-l' to list all enzymes, '-n' for non-interactive output\n",
    "        # Adding timeout to prevent hanging if RPG has issues\n",
    "        result = subprocess.run(['rpg', '-l', '-n'], capture_output=True, text=True, check=True, timeout=10)\n",
    "        defined_enzymes_output = result.stdout\n",
    "        for line in defined_enzymes_output.splitlines():\n",
    "            parts = line.strip().split(maxsplit=2) \n",
    "            if len(parts) >= 2 and parts[0].isdigit():\n",
    "                all_available_caspase_names.add(parts[1].strip())\n",
    "        print(f\"Existing RPG enzymes found: {all_available_caspase_names}\")\n",
    "    except (subprocess.CalledProcessError, subprocess.TimeoutExpired) as e:\n",
    "        print(f\"Warning: Error or timeout listing RPG enzymes. Details: {e}\")\n",
    "        if isinstance(e, subprocess.CalledProcessError):\n",
    "            print(f\"Stderr: {e.stderr.strip()}\")\n",
    "        print(\"Could not retrieve existing enzyme names reliably. Proceeding by attempting definition for all.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: 'rpg' command not found. Please ensure RPG is installed and in your PATH.\")\n",
    "        return set()\n",
    "\n",
    "    for caspase_name, cleavage_rule_rpg_syntax in caspase_rules.items():\n",
    "        if caspase_name in all_available_caspase_names:\n",
    "            print(f\"Enzyme '{caspase_name}' already listed by RPG. Skipping definition.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Attempting to define new enzyme: '{caspase_name}' with rule '{cleavage_rule_rpg_syntax}'...\")\n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                ['rpg', '-a', '-n', '-y', caspase_name, '-x', cleavage_rule_rpg_syntax],\n",
    "                capture_output=True, text=True, check=False, timeout=10\n",
    "            )\n",
    "            if result.returncode == 0:\n",
    "                print(f\"Successfully defined '{caspase_name}'.\")\n",
    "                all_available_caspase_names.add(caspase_name)\n",
    "            elif \"This name exist\" in result.stderr:\n",
    "                print(f\"Enzyme '{caspase_name}' already exists (as reported by RPG's stderr). Skipping definition.\")\n",
    "                all_available_caspase_names.add(caspase_name)\n",
    "            else:\n",
    "                print(f\"ERROR defining '{caspase_name}': {result.stderr.strip()}\")\n",
    "        except subprocess.TimeoutExpired:\n",
    "             print(f\"Timeout occurred while defining '{caspase_name}'.\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"Error: 'rpg' command not found during enzyme definition.\")\n",
    "            return set()\n",
    "\n",
    "    return all_available_caspase_names\n",
    "\n",
    "def run_rpg_digestion(input_fasta_path, caspase_name, output_csv_path):\n",
    "    \"\"\"\n",
    "    Runs RPG as a subprocess for a single caspase and saves results to CSV.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        subprocess.run(\n",
    "            ['rpg', '-i', input_fasta_path, '-e', caspase_name, '-f', 'csv', '-n', '-o', output_csv_path, '-d', 'sequential'],\n",
    "            check=True,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=300 \n",
    "        )\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error running RPG for '{caspase_name}':\")\n",
    "        print(f\"  Command: {' '.join(e.cmd)}\")\n",
    "        print(f\"  Return Code: {e.returncode}\")\n",
    "        print(f\"  Stdout: {e.stdout.strip()}\")\n",
    "        print(f\"  Stderr: {e.stderr.strip()}\")\n",
    "        return False\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"Timeout occurred while running RPG for '{caspase_name}'.\")\n",
    "        return False\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: 'rpg' command not found. Please ensure RPG is installed and in your PATH.\")\n",
    "        return False\n",
    "\n",
    "# New helper functions for the updated pipeline\n",
    "def parse_fasta(fasta_file):\n",
    "    \"\"\"\n",
    "    Parses a FASTA file and returns a dictionary of {ncbi_id: sequence}.\n",
    "    Assumes header format is <ncbi_id>|<description>.\n",
    "    \"\"\"\n",
    "    print(f\"Parsing FASTA file: {fasta_file}\")\n",
    "    sequences = {}\n",
    "    try:\n",
    "        for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "            ncbi_id = record.id.split('|')[0] # Extract NCBI ID from header\n",
    "            sequences[ncbi_id] = str(record.seq)\n",
    "        print(f\"Found {len(sequences)} sequences in FASTA.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing FASTA file {fasta_file}: {e}\")\n",
    "    return sequences\n",
    "\n",
    "def load_and_filter_excel(excel_file, sheet_name='RITA'):\n",
    "    \"\"\"\n",
    "    Loads and filters the Excel sheet based on 'type' and 'sig' columns.\n",
    "    \"\"\"\n",
    "    print(f\"Loading Excel file: {excel_file}, sheet: {sheet_name}\")\n",
    "    try:\n",
    "        df_rita = pd.read_excel(excel_file, sheet_name=sheet_name, engine=\"openpyxl\")\n",
    "        original_rows = len(df_rita)\n",
    "        print(f\"Original rows in '{sheet_name}': {original_rows}\")\n",
    "\n",
    "        df_filtered = df_rita[\n",
    "            (df_rita['type'].isin(['VP', 'VT'])) &\n",
    "            (df_rita['sig'] == 'Yes')\n",
    "        ].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
    "        \n",
    "        print(f\"Filtered rows (type in [VP, VT] and sig=Yes): {len(df_filtered)}\")\n",
    "        return df_filtered\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Excel file not found at {excel_file}\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or filtering Excel sheet '{sheet_name}' from {excel_file}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def process_protein_cleavages(unique_proteins_fasta_path, caspase_motifs_rpg, currently_available_rpg_enzymes, temp_dir):\n",
    "    \"\"\"\n",
    "    Runs RPG for all available caspases on a unique set of proteins\n",
    "    and collects all cleavage sites.\n",
    "    Returns a dictionary: {protein_id: {'caspases': [list_of_caspases], 'cleavage_sites': [sorted_list_of_1based_positions]}}\n",
    "    \"\"\"\n",
    "    print(\"Processing unique proteins for caspase cleavage sites...\")\n",
    "    all_protein_cleavage_data = {}\n",
    "\n",
    "    CLEAVAGE_POS_COL = 'Cleaving_pos' \n",
    "    HEADER_COL = 'Original_header'\n",
    "\n",
    "    for caspase_name, motif_rule_rpg_syntax in caspase_motifs_rpg.items():\n",
    "        if caspase_name not in currently_available_rpg_enzymes:\n",
    "            print(f\"Skipping RPG digestion for '{caspase_name}' as it's not defined or available.\")\n",
    "            continue\n",
    "        \n",
    "        # motif_str is not used here but could be for debugging, it's derived later\n",
    "        temp_output_csv = os.path.join(temp_dir, f'rpg_output_{caspase_name}.csv')\n",
    "        \n",
    "        print(f\"  Running RPG for '{caspase_name}'...\") # Added this for more granularity\n",
    "        if run_rpg_digestion(unique_proteins_fasta_path, caspase_name, temp_output_csv):\n",
    "            try:\n",
    "                df_rpg_output = pd.read_csv(temp_output_csv)\n",
    "                \n",
    "                if CLEAVAGE_POS_COL not in df_rpg_output.columns:\n",
    "                    print(f\"ERROR: Expected column '{CLEAVAGE_POS_COL}' not found in RPG output for '{caspase_name}'.\")\n",
    "                    print(f\"Actual columns found: {df_rpg_output.columns.tolist()}\")\n",
    "                    continue\n",
    "                if HEADER_COL not in df_rpg_output.columns:\n",
    "                     print(f\"ERROR: Expected header column '{HEADER_COL}' not found in RPG output for '{caspase_name}'.\")\n",
    "                     continue\n",
    "                \n",
    "                cleaved_peptides = df_rpg_output[\n",
    "                    df_rpg_output[CLEAVAGE_POS_COL] > 0\n",
    "                ]\n",
    "\n",
    "                for index, row in cleaved_peptides.iterrows():\n",
    "                    header_parts = str(row[HEADER_COL]).split('_')\n",
    "                    original_protein_id = header_parts[0]\n",
    "\n",
    "                    cleavage_point_1_based = int(row[CLEAVAGE_POS_COL])\n",
    "\n",
    "                    if original_protein_id not in all_protein_cleavage_data:\n",
    "                        all_protein_cleavage_data[original_protein_id] = {'caspases': set(), 'cleavage_sites': set()}\n",
    "                    \n",
    "                    all_protein_cleavage_data[original_protein_id]['caspases'].add(caspase_name)\n",
    "                    all_protein_cleavage_data[original_protein_id]['cleavage_sites'].add(cleavage_point_1_based)\n",
    "\n",
    "            except pd.errors.EmptyDataError:\n",
    "                pass # No cleavage sites in this file, which is fine\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading or parsing RPG output for '{caspase_name}' from {temp_output_csv}: {e}\")\n",
    "    \n",
    "    # Convert sets to sorted lists for consistent output\n",
    "    for protein_id, data in all_protein_cleavage_data.items():\n",
    "        data['caspases'] = sorted(list(data['caspases']))\n",
    "        data['cleavage_sites'] = sorted(list(data['cleavage_sites']))\n",
    "    \n",
    "    print(\"Finished processing unique proteins for caspase cleavage sites.\")\n",
    "    return all_protein_cleavage_data\n",
    "\n",
    "def get_cleavage_analysis(protein_seq, tile_seq, all_caspase_cleavage_data):\n",
    "    \"\"\"\n",
    "    Analyzes tile cleavage and distance to nearest cleavage site.\n",
    "    Cleavage at position P means the bond *after* residue P is broken.\n",
    "    \"\"\"\n",
    "    protein_cleavable = False\n",
    "    caspases_list = []\n",
    "    full_protein_cleavage_sites_list = []\n",
    "    \n",
    "    if all_caspase_cleavage_data: # If there's any cleavage data for the protein\n",
    "        protein_cleavable = True\n",
    "        caspases_list = all_caspase_cleavage_data['caspases']\n",
    "        full_protein_cleavage_sites_list = all_caspase_cleavage_data['cleavage_sites']\n",
    "    \n",
    "    tile_cut = False\n",
    "    tile_in_x_snip = \"N/A\"\n",
    "    distance_nearest_cleave = \"N/A\"\n",
    "\n",
    "    if not protein_seq or not tile_seq:\n",
    "        return protein_cleavable, \", \".join(caspases_list), full_protein_cleavage_sites_list, \\\n",
    "               tile_cut, tile_in_x_snip, distance_nearest_cleave\n",
    "\n",
    "    # Find tile position in the full protein sequence (0-based)\n",
    "    tile_start_0based = protein_seq.find(tile_seq)\n",
    "    \n",
    "    if tile_start_0based == -1:\n",
    "        # Tile not found in the protein sequence\n",
    "        tile_in_x_snip = \"Tile not found in protein\"\n",
    "        return protein_cleavable, \", \".join(caspases_list), full_protein_cleavage_sites_list, \\\n",
    "               tile_cut, tile_in_x_snip, distance_nearest_cleave\n",
    "\n",
    "    tile_end_0based = tile_start_0based + len(tile_seq)\n",
    "\n",
    "    # Convert to 1-based for consistent comparison with cleavage sites\n",
    "    tile_start_1based = tile_start_0based + 1\n",
    "    tile_end_1based = tile_end_0based # This is the 1-based index of the *last residue* in the tile\n",
    "\n",
    "    if full_protein_cleavage_sites_list:\n",
    "        # Check if tile itself is cut\n",
    "        for cp in full_protein_cleavage_sites_list:\n",
    "            # A cleavage at 'cp' breaks the bond *after* residue 'cp'.\n",
    "            # If cp is between the tile's start and its second-to-last residue, the tile is cut.\n",
    "            # Condition: cleavage_point is after tile's start and before tile's end\n",
    "            if tile_start_1based <= cp < tile_end_1based:\n",
    "                tile_cut = True\n",
    "                break\n",
    "        \n",
    "        # If tile not cut, find snippet and distance\n",
    "        if not tile_cut:\n",
    "            # Find the closest cleavage point before the tile's start\n",
    "            cleavages_before_tile_start = [cp for cp in full_protein_cleavage_sites_list if cp < tile_start_1based]\n",
    "            # The start of the snippet will be (nearest_cleavage_before + 1), or 1 if no cleavage before.\n",
    "            snippet_start_1based = (max(cleavages_before_tile_start) + 1) if cleavages_before_tile_start else 1\n",
    "\n",
    "            # Find the closest cleavage point after the tile's end\n",
    "            cleavages_after_tile_end = [cp for cp in full_protein_cleavage_sites_list if cp >= tile_end_1based]\n",
    "            # The end of the snippet will be (nearest_cleavage_after), or len(protein_seq) if no cleavage after.\n",
    "            snippet_end_1based = min(cleavages_after_tile_end) if cleavages_after_tile_end else len(protein_seq)\n",
    "\n",
    "            tile_in_x_snip = f\"{snippet_start_1based}-{snippet_end_1based}\"\n",
    "\n",
    "            # Calculate distance to nearest cleavage outside the tile\n",
    "            distances_outside = []\n",
    "            if cleavages_before_tile_start:\n",
    "                # Distance from tile's start to the closest cleavage point before it\n",
    "                distances_outside.append(tile_start_1based - max(cleavages_before_tile_start) - 1)\n",
    "            \n",
    "            if cleavages_after_tile_end:\n",
    "                # Distance from tile's end to the closest cleavage point after it\n",
    "                distances_outside.append(min(cleavages_after_tile_end) - tile_end_1based)\n",
    "            \n",
    "            if distances_outside:\n",
    "                distance_nearest_cleave = min(d for d in distances_outside if d >= 0) # Ensure distance is non-negative\n",
    "            else:\n",
    "                distance_nearest_cleave = \"No cleavages outside tile\"\n",
    "    else:\n",
    "        # No cleavages in the entire protein\n",
    "        tile_in_x_snip = f\"1-{len(protein_seq)}\"\n",
    "        distance_nearest_cleave = \"No cleavages in protein\"\n",
    "\n",
    "\n",
    "    return protein_cleavable, \", \".join(caspases_list), full_protein_cleavage_sites_list, \\\n",
    "           tile_cut, tile_in_x_snip, distance_nearest_cleave\n",
    "\n",
    "# Main pipeline function\n",
    "def main_pipeline(fasta_file_path, excel_file_path, output_csv_path):\n",
    "    # 1. Define Caspase Enzymes in RPG\n",
    "    # Appended '_consens' to names for clarity and to ensure they are user-defined.\n",
    "    caspase_motifs_rpg = {\n",
    "        'Caspase-2_consens': '(V)(D)(V)(A)(D,)',\n",
    "        'Caspase-3_consens': '(D)(E)(V)(D,)',\n",
    "        'Caspase-6_consens': '(V)(E)(H)(D,)',\n",
    "        'Caspase-7_consens': '(D)(E)(V)(D,)', \n",
    "        'Caspase-8_consens': '(I)(E)(T)(D,)',\n",
    "        'Caspase-9_consens': '(L)(E)(H)(D,)',\n",
    "        'Caspase-10_consens': '(A)(E)(V)(D,)'\n",
    "    }\n",
    "    currently_available_rpg_enzymes = define_caspase_enzymes(caspase_motifs_rpg)\n",
    "    \n",
    "    if not currently_available_rpg_enzymes:\n",
    "        print(\"Critical Error: No caspase enzymes are available for digestion. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # 2. Parse FASTA file\n",
    "    ncbi_fasta_sequences = parse_fasta(fasta_file_path)\n",
    "    if not ncbi_fasta_sequences:\n",
    "        print(\"Critical Error: No sequences parsed from FASTA file. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # 3. Load and Filter Excel Data\n",
    "    df_filtered_excel = load_and_filter_excel(excel_file_path, sheet_name='RITA')\n",
    "    if df_filtered_excel.empty:\n",
    "        print(\"Critical Error: No data found or filtered from Excel sheet. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # 4. Merge Excel data with FASTA sequences\n",
    "    # Add 'Protein_seq' column to the filtered DataFrame\n",
    "    df_filtered_excel['Protein_seq'] = df_filtered_excel['NCBI_id'].map(ncbi_fasta_sequences)\n",
    "    \n",
    "    # Remove rows where NCBI_id did not match a FASTA sequence\n",
    "    df_analysis = df_filtered_excel.dropna(subset=['Protein_seq']).copy()\n",
    "    num_unmatched = len(df_filtered_excel) - len(df_analysis)\n",
    "    if num_unmatched > 0:\n",
    "        print(f\"Warning: {num_unmatched} rows from Excel could not be matched to FASTA sequences by NCBI_id and were dropped.\")\n",
    "    \n",
    "    if df_analysis.empty:\n",
    "        print(\"Critical Error: No matched protein sequences for analysis. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # 5. Prepare unique proteins for RPG\n",
    "    unique_protein_data = df_analysis[['NCBI_id', 'Protein_seq']].drop_duplicates().set_index('NCBI_id')\n",
    "    \n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    unique_proteins_fasta_path = os.path.join(temp_dir, 'unique_proteins_for_rpg.fasta')\n",
    "\n",
    "    with open(unique_proteins_fasta_path, 'w') as f:\n",
    "        for ncbi_id, row in unique_protein_data.iterrows():\n",
    "            f.write(f\">{ncbi_id}\\n{row['Protein_seq']}\\n\")\n",
    "    print(f\"Unique proteins ({len(unique_protein_data)}) written to temporary FASTA: {unique_proteins_fasta_path}\")\n",
    "\n",
    "    # 6. Run RPG for all caspases on unique proteins and collect results\n",
    "    print(\"Initiating RPG digestion for all relevant caspases on unique proteins...\")\n",
    "    all_protein_cleavage_results = process_protein_cleavages(\n",
    "        unique_proteins_fasta_path, caspase_motifs_rpg, currently_available_rpg_enzymes, temp_dir\n",
    "    )\n",
    "    print(\"RPG digestion and result collection complete.\")\n",
    "\n",
    "    # 7. Analyze each row of the filtered Excel data\n",
    "    results_for_output = []\n",
    "    print(\"Analyzing tiles and generating final output rows...\")\n",
    "    for index, row in df_analysis.iterrows():\n",
    "        ncbi_id = row['NCBI_id']\n",
    "        protein_seq = row['Protein_seq']\n",
    "        \n",
    "        # --- NEW CHANGE: Remove leading 'M' from Aminoacids (tile_seq) ---\n",
    "        original_tile_seq = row['Aminoacids']\n",
    "        tile_seq = original_tile_seq[1:] if original_tile_seq.startswith('M') else original_tile_seq\n",
    "        # --- END NEW CHANGE ---\n",
    "\n",
    "        cleavage_data_for_protein = all_protein_cleavage_results.get(ncbi_id, {})\n",
    "        \n",
    "        # Perform tile-specific cleavage analysis\n",
    "        protein_cleavable, caspases_str, cleavage_sites_list, tile_cut, tile_in_x_snip, distance_nearest_cleave = \\\n",
    "            get_cleavage_analysis(protein_seq, tile_seq, cleavage_data_for_protein)\n",
    "\n",
    "        # Prepare the output row\n",
    "        output_row = row.to_dict() # Start with existing Excel columns\n",
    "        output_row.update({\n",
    "            'Protein_Cleavable': protein_cleavable,\n",
    "            'Caspases': caspases_str,\n",
    "            'Cleavag_sites': \", \".join(map(str, cleavage_sites_list)) if cleavage_sites_list else \"None\",\n",
    "            'tile_cut': tile_cut,\n",
    "            'tile_in_x_snip': tile_in_x_snip,\n",
    "            'distance_nearest_cleave': distance_nearest_cleave,\n",
    "            'Protein_seq': protein_seq\n",
    "        })\n",
    "        results_for_output.append(output_row)\n",
    "\n",
    "    # 8. Create and Save Final Output DataFrame\n",
    "    df_final_output = pd.DataFrame(results_for_output)\n",
    "    \n",
    "    # Select and reorder columns as per user request\n",
    "    final_columns = [\n",
    "        'tileID', 'log2FoldChange', 'padj', 'type', 'sig', 'Virus', 'NCBI_id', 'Uniprot_id', 'Gene_name', 'Aminoacids',\n",
    "        'Protein_Cleavable', 'Caspases', 'Cleavag_sites', 'tile_cut', 'tile_in_x_snip', 'distance_nearest_cleave', 'Protein_seq'\n",
    "    ]\n",
    "    # Ensure all requested columns exist, fill missing with 'None' if any were somehow not added\n",
    "    for col in final_columns:\n",
    "        if col not in df_final_output.columns:\n",
    "            df_final_output[col] = 'None' # Or pd.NA, depending on desired type\n",
    "\n",
    "    df_final_output = df_final_output[final_columns]\n",
    "    df_final_output = df_final_output.fillna('None') # Final pass for any NaNs\n",
    "\n",
    "    try:\n",
    "        df_final_output.to_csv(output_csv_path, index=False)\n",
    "        print(f\"\\nPipeline complete. Results saved to {output_csv_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving final output CSV: {e}\")\n",
    "    finally:\n",
    "        # Clean up temporary files and directory\n",
    "        try:\n",
    "            for f in os.listdir(temp_dir):\n",
    "                os.remove(os.path.join(temp_dir, f))\n",
    "            os.rmdir(temp_dir)\n",
    "            print(f\"Cleaned up temporary directory: {temp_dir}\")\n",
    "        except OSError as e:\n",
    "            print(f\"Error cleaning up temporary directory {temp_dir}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fasta_input = 'data/all_virus_proteins.fasta'\n",
    "    excel_input = 'data/RITA_and_ABT_pos_selection_screens.xlsx'\n",
    "    output_final_csv = 'results/RITA_virus_caspase_analysis.csv'\n",
    "    \n",
    "    main_pipeline(fasta_input, excel_input, output_final_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run with full caspase library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing all available RPG enzymes...\n",
      "Found 54 enzymes in RPG.\n",
      "Parsing FASTA file: data/all_virus_proteins.fasta\n",
      "Found 1522 sequences in FASTA.\n",
      "Loading Excel file: data/RITA_and_ABT_pos_selection_screens.xlsx, sheet: RITA\n",
      "Original rows in 'RITA': 32721\n",
      "Filtered rows (type in [VP, VT] and sig=Yes): 498\n",
      "Warning: 30 rows from Excel could not be matched to FASTA sequences by NCBI_id and were dropped.\n",
      "Unique proteins (324) written to temporary FASTA: /scratch/872575.1.mnemosyne-pub/tmpukublb_v/unique_proteins_for_rpg.fasta\n",
      "Initiating RPG digestion for all available enzymes on unique proteins...\n",
      "Processing unique proteins for enzyme cleavage sites...\n",
      "  Running RPG for 'Arg-C'...\n",
      "  Running RPG for 'Asp-N'...\n",
      "  Running RPG for 'BNPS-Skatole'...\n",
      "  Running RPG for 'Bromelain'...\n",
      "  Running RPG for 'Caspase-1'...\n",
      "  Running RPG for 'Caspase-2'...\n",
      "  Running RPG for 'Caspase-3'...\n",
      "  Running RPG for 'Caspase-4'...\n",
      "  Running RPG for 'Caspase-5'...\n",
      "  Running RPG for 'Caspase-6'...\n",
      "  Running RPG for 'Caspase-7'...\n",
      "  Running RPG for 'Caspase-8'...\n",
      "  Running RPG for 'Caspase-9'...\n",
      "  Running RPG for 'Caspase-10'...\n",
      "  Running RPG for 'Chymotrypsin-high'...\n",
      "  Running RPG for 'Chymotrypsin-low'...\n",
      "  Running RPG for 'Clostripain'...\n",
      "  Running RPG for 'CNBr'...\n",
      "  Running RPG for 'Enterokinase'...\n",
      "  Running RPG for 'Factor-Xa'...\n",
      "  Running RPG for 'Ficin'...\n",
      "  Running RPG for 'Formic-acid'...\n",
      "  Running RPG for 'Glu-C'...\n",
      "  Running RPG for 'Glutamyl-endopeptidase'...\n",
      "  Running RPG for 'Granzyme-B'...\n",
      "  Running RPG for 'Hydroxylamine'...\n",
      "  Running RPG for 'Iodosobenzoic-acid'...\n",
      "  Running RPG for 'Lys-C'...\n",
      "  Running RPG for 'Lys-N'...\n",
      "  Running RPG for 'Neutrophil-elastase'...\n",
      "  Running RPG for 'NTCB'...\n",
      "  Running RPG for 'Papain'...\n",
      "  Running RPG for 'Pepsin-pH1.3'...\n",
      "  Running RPG for 'Pepsin-pH>=2'...\n",
      "  Running RPG for 'Proline-endopeptidase'...\n",
      "  Running RPG for 'Proteinase-K'...\n",
      "  Running RPG for 'Staphylococcal-peptidase-I'...\n",
      "  Running RPG for 'Thermolysin'...\n",
      "  Running RPG for 'Thrombin'...\n",
      "  Running RPG for 'Thrombin-SG'...\n",
      "  Running RPG for 'Tobacco-Etch-Virus'...\n",
      "  Running RPG for 'Trypsin'...\n",
      "  Running RPG for 'Asp-N Endopeptidase'...\n",
      "  Running RPG for 'ProAlanase'...\n",
      "  Running RPG for 'Elastase'...\n",
      "  Running RPG for 'aLP'...\n",
      "  Running RPG for 'Caspase-2_consens'...\n",
      "  Running RPG for 'Caspase-3and7_consens'...\n",
      "  Running RPG for 'Caspase-6_consens'...\n",
      "  Running RPG for 'Caspase-8_consens'...\n",
      "  Running RPG for 'Caspase-9_consens'...\n",
      "  Running RPG for 'Caspase-10_consens'...\n",
      "  Running RPG for 'Caspase-3_consens'...\n",
      "  Running RPG for 'Caspase-7_consens'...\n",
      "Finished processing unique proteins for enzyme cleavage sites.\n",
      "RPG digestion and result collection complete.\n",
      "Analyzing tiles and generating final output rows (per enzyme)...\n",
      "\n",
      "Pipeline complete. Results saved to results/RITA_virus_cleavage_analysis.csv\n",
      "Cleaned up temporary directory: /scratch/872575.1.mnemosyne-pub/tmpukublb_v\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "import tempfile\n",
    "from Bio import SeqIO # Using Biopython for robust FASTA parsing\n",
    "import numpy as np # For numerical operations, especially distances\n",
    "\n",
    "# Re-using functions from the previous script\n",
    "def get_all_rpg_enzymes():\n",
    "    \"\"\"\n",
    "    Lists all enzymes available in RPG using 'rpg -l'.\n",
    "    Returns a dictionary {enzyme_name: enzyme_id}.\n",
    "    \"\"\"\n",
    "    print(\"Listing all available RPG enzymes...\")\n",
    "    all_enzymes = {}\n",
    "    try:\n",
    "        # We confirmed 'rpg -l' works directly and its output is what we want to capture.\n",
    "        result = subprocess.run(['rpg', '-l'], capture_output=True, text=True, check=True, timeout=10)\n",
    "        \n",
    "        # You can add this line to see the raw output being parsed, for debugging\n",
    "        # print(\"--- Raw RPG -l Output ---\")\n",
    "        # print(result.stdout)\n",
    "        # print(\"--- End Raw RPG Output ---\")\n",
    "\n",
    "        if result.stderr:\n",
    "            print(f\"RPG stderr output during enzyme listing: {result.stderr.strip()}\")\n",
    "\n",
    "        for line in result.stdout.splitlines():\n",
    "            # Example line: \"1: Arg-C\"\n",
    "            parts = line.strip().split(':', 1) # Split only at the first colon\n",
    "            if len(parts) >= 2:\n",
    "                enzyme_id = parts[0].strip() # This will be \"1\"\n",
    "                enzyme_name = parts[1].strip() # This will be \"Arg-C\"\n",
    "\n",
    "                # No need for .replace('.', '') anymore, as we split on ':'\n",
    "                # and .strip() removes whitespace.\n",
    "                # Just ensure it's a digit now.\n",
    "                if enzyme_id.isdigit():\n",
    "                    all_enzymes[enzyme_name] = enzyme_id\n",
    "        print(f\"Found {len(all_enzymes)} enzymes in RPG.\")\n",
    "    except (subprocess.CalledProcessError, subprocess.TimeoutExpired) as e:\n",
    "        print(f\"Warning: Error or timeout listing RPG enzymes. Details: {e}\")\n",
    "        if isinstance(e, subprocess.CalledProcessError):\n",
    "            print(f\"Stderr: {e.stderr.strip()}\")\n",
    "        print(\"Could not retrieve existing enzyme names reliably.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: 'rpg' command not found. Please ensure RPG is installed and in your PATH.\")\n",
    "    return all_enzymes\n",
    "\n",
    "def run_rpg_digestion(input_fasta_path, enzyme_name, output_csv_path): # Changed parameter name\n",
    "    \"\"\"\n",
    "    Runs RPG as a subprocess for a single enzyme and saves results to CSV. # Updated docstring\n",
    "    \"\"\"\n",
    "    try:\n",
    "        subprocess.run(\n",
    "            ['rpg', '-i', input_fasta_path, '-e', enzyme_name, '-f', 'csv', '-n', '-o', output_csv_path, '-d', 'sequential'], # Used new parameter name\n",
    "            check=True,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=300 \n",
    "        )\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error running RPG for '{enzyme_name}':\") # Used new parameter name\n",
    "        print(f\"  Command: {' '.join(e.cmd)}\")\n",
    "        print(f\"  Return Code: {e.returncode}\")\n",
    "        print(f\"  Stdout: {e.stdout.strip()}\")\n",
    "        print(f\"  Stderr: {e.stderr.strip()}\")\n",
    "        return False\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"Timeout occurred while running RPG for '{enzyme_name}'.\") # Used new parameter name\n",
    "        return False\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: 'rpg' command not found. Please ensure RPG is installed and in your PATH.\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# New helper functions for the updated pipeline\n",
    "def parse_fasta(fasta_file):\n",
    "    \"\"\"\n",
    "    Parses a FASTA file and returns a dictionary of {ncbi_id: sequence}.\n",
    "    Assumes header format is <ncbi_id>|<description>.\n",
    "    \"\"\"\n",
    "    print(f\"Parsing FASTA file: {fasta_file}\")\n",
    "    sequences = {}\n",
    "    try:\n",
    "        for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "            ncbi_id = record.id.split('|')[0] # Extract NCBI ID from header\n",
    "            sequences[ncbi_id] = str(record.seq)\n",
    "        print(f\"Found {len(sequences)} sequences in FASTA.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing FASTA file {fasta_file}: {e}\")\n",
    "    return sequences\n",
    "\n",
    "def load_and_filter_excel(excel_file, sheet_name='RITA'):\n",
    "    \"\"\"\n",
    "    Loads and filters the Excel sheet based on 'type' and 'sig' columns.\n",
    "    \"\"\"\n",
    "    print(f\"Loading Excel file: {excel_file}, sheet: {sheet_name}\")\n",
    "    try:\n",
    "        df_rita = pd.read_excel(excel_file, sheet_name=sheet_name, engine=\"openpyxl\")\n",
    "        original_rows = len(df_rita)\n",
    "        print(f\"Original rows in '{sheet_name}': {original_rows}\")\n",
    "\n",
    "        df_filtered = df_rita[\n",
    "            (df_rita['type'].isin(['VP', 'VT'])) &\n",
    "            (df_rita['sig'] == 'Yes')\n",
    "        ].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
    "        \n",
    "        print(f\"Filtered rows (type in [VP, VT] and sig=Yes): {len(df_filtered)}\")\n",
    "        return df_filtered\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Excel file not found at {excel_file}\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or filtering Excel sheet '{sheet_name}' from {excel_file}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def process_protein_cleavages(unique_proteins_fasta_path, all_rpg_enzymes_dict, temp_dir):\n",
    "    \"\"\"\n",
    "    Runs RPG for all available enzymes on a unique set of proteins\n",
    "    and collects all cleavage sites, organized by protein and then by enzyme.\n",
    "    Returns a dictionary: {protein_id: {enzyme_name: {'cleavage_sites': [sorted_list_of_1based_positions]}}}\n",
    "    \"\"\"\n",
    "    print(\"Processing unique proteins for enzyme cleavage sites...\")\n",
    "    # New structure: protein_id -> enzyme_name -> {'cleavage_sites': set()}\n",
    "    all_protein_cleavage_data = {}\n",
    "\n",
    "    CLEAVAGE_POS_COL = 'Cleaving_pos' \n",
    "    HEADER_COL = 'Original_header'\n",
    "\n",
    "    for enzyme_name in all_rpg_enzymes_dict.keys(): \n",
    "        temp_output_csv = os.path.join(temp_dir, f'rpg_output_{enzyme_name}.csv')\n",
    "        \n",
    "        print(f\"  Running RPG for '{enzyme_name}'...\")\n",
    "        if run_rpg_digestion(unique_proteins_fasta_path, enzyme_name, temp_output_csv):\n",
    "            try:\n",
    "                df_rpg_output = pd.read_csv(temp_output_csv)\n",
    "                \n",
    "                if CLEAVAGE_POS_COL not in df_rpg_output.columns:\n",
    "                    print(f\"ERROR: Expected column '{CLEAVAGE_POS_COL}' not found in RPG output for '{enzyme_name}'.\")\n",
    "                    print(f\"Actual columns found: {df_rpg_output.columns.tolist()}\")\n",
    "                    continue\n",
    "                if HEADER_COL not in df_rpg_output.columns:\n",
    "                     print(f\"ERROR: Expected header column '{HEADER_COL}' not found in RPG output for '{enzyme_name}'.\")\n",
    "                     continue\n",
    "                \n",
    "                cleaved_peptides = df_rpg_output[\n",
    "                    df_rpg_output[CLEAVAGE_POS_COL] > 0\n",
    "                ]\n",
    "\n",
    "                for index, row in cleaved_peptides.iterrows():\n",
    "                    header_parts = str(row[HEADER_COL]).split('_')\n",
    "                    original_protein_id = header_parts[0]\n",
    "\n",
    "                    cleavage_point_1_based = int(row[CLEAVAGE_POS_COL])\n",
    "\n",
    "                    if original_protein_id not in all_protein_cleavage_data:\n",
    "                        all_protein_cleavage_data[original_protein_id] = {}\n",
    "                    \n",
    "                    if enzyme_name not in all_protein_cleavage_data[original_protein_id]:\n",
    "                        all_protein_cleavage_data[original_protein_id][enzyme_name] = {'cleavage_sites': set()}\n",
    "                    \n",
    "                    all_protein_cleavage_data[original_protein_id][enzyme_name]['cleavage_sites'].add(cleavage_point_1_based)\n",
    "\n",
    "            except pd.errors.EmptyDataError:\n",
    "                pass # No cleavage sites in this file for this enzyme, which is fine\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading or parsing RPG output for '{enzyme_name}' from {temp_output_csv}: {e}\")\n",
    "    \n",
    "    # Convert sets to sorted lists for consistent output\n",
    "    for protein_id, enzyme_data in all_protein_cleavage_data.items():\n",
    "        for enzyme_name, data in enzyme_data.items():\n",
    "            data['cleavage_sites'] = sorted(list(data['cleavage_sites']))\n",
    "    \n",
    "    print(\"Finished processing unique proteins for enzyme cleavage sites.\") \n",
    "    return all_protein_cleavage_data\n",
    "\n",
    "\n",
    "def get_cleavage_analysis(protein_seq, tile_seq, enzyme_cleavage_sites_list): # Changed argument name\n",
    "    \"\"\"\n",
    "    Analyzes tile cleavage and distance to nearest cleavage site for a SINGLE enzyme.\n",
    "    Cleavage at position P means the bond *after* residue P is broken.\n",
    "    \"\"\"\n",
    "    # protein_cleavable refers to whether THIS SPECIFIC enzyme has ANY cleavage site in the protein.\n",
    "    protein_cleavable_by_enzyme = bool(enzyme_cleavage_sites_list)\n",
    "    \n",
    "    tile_cut = False\n",
    "    tile_in_x_snip = \"N/A\"\n",
    "    distance_nearest_cleave = \"N/A\"\n",
    "\n",
    "    if not protein_seq or not tile_seq:\n",
    "        # If no protein or tile sequence, cannot analyze\n",
    "        return protein_cleavable_by_enzyme, enzyme_cleavage_sites_list, \\\n",
    "               tile_cut, tile_in_x_snip, distance_nearest_cleave\n",
    "\n",
    "    # Find tile position in the full protein sequence (0-based)\n",
    "    tile_start_0based = protein_seq.find(tile_seq)\n",
    "    \n",
    "    if tile_start_0based == -1:\n",
    "        # Tile not found in the protein sequence\n",
    "        tile_in_x_snip = \"Tile not found in protein\"\n",
    "        return protein_cleavable_by_enzyme, enzyme_cleavage_sites_list, \\\n",
    "               tile_cut, tile_in_x_snip, distance_nearest_cleave\n",
    "\n",
    "    tile_end_0based = tile_start_0based + len(tile_seq)\n",
    "\n",
    "    # Convert to 1-based for consistent comparison with cleavage sites\n",
    "    tile_start_1based = tile_start_0based + 1\n",
    "    tile_end_1based = tile_end_0based # This is the 1-based index of the *last residue* in the tile\n",
    "\n",
    "    if enzyme_cleavage_sites_list: # If this specific enzyme cleaves the protein at all\n",
    "        # Check if tile itself is cut by this enzyme\n",
    "        for cp in enzyme_cleavage_sites_list:\n",
    "            if tile_start_1based <= cp < tile_end_1based:\n",
    "                tile_cut = True\n",
    "                break\n",
    "        \n",
    "        # If tile not cut, find snippet and distance (specific to this enzyme's cleavages)\n",
    "        if not tile_cut:\n",
    "            cleavages_before_tile_start = [cp for cp in enzyme_cleavage_sites_list if cp < tile_start_1based]\n",
    "            snippet_start_1based = (max(cleavages_before_tile_start) + 1) if cleavages_before_tile_start else 1\n",
    "\n",
    "            cleavages_after_tile_end = [cp for cp in enzyme_cleavage_sites_list if cp >= tile_end_1based]\n",
    "            snippet_end_1based = min(cleavages_after_tile_end) if cleavages_after_tile_end else len(protein_seq)\n",
    "\n",
    "            tile_in_x_snip = f\"{snippet_start_1based}-{snippet_end_1based}\"\n",
    "\n",
    "            distances_outside = []\n",
    "            if cleavages_before_tile_start:\n",
    "                distances_outside.append(tile_start_1based - max(cleavages_before_tile_start) - 1)\n",
    "            \n",
    "            if cleavages_after_tile_end:\n",
    "                distances_outside.append(min(cleavages_after_tile_end) - tile_end_1based)\n",
    "            \n",
    "            if distances_outside:\n",
    "                distance_nearest_cleave = min(d for d in distances_outside if d >= 0) \n",
    "            else:\n",
    "                distance_nearest_cleave = \"No cleavages outside tile\"\n",
    "    else:\n",
    "        # No cleavages by this specific enzyme in the entire protein\n",
    "        tile_in_x_snip = f\"1-{len(protein_seq)}\"\n",
    "        distance_nearest_cleave = \"No cleavages by this enzyme\"\n",
    "\n",
    "\n",
    "    return protein_cleavable_by_enzyme, enzyme_cleavage_sites_list, \\\n",
    "           tile_cut, tile_in_x_snip, distance_nearest_cleave\n",
    "\n",
    "# Main pipeline function\n",
    "def main_pipeline(fasta_file_path, excel_file_path, output_csv_path):\n",
    "    # 1. Get all available RPG enzymes (built-in and user-defined)\n",
    "    all_rpg_enzymes_dict = get_all_rpg_enzymes()\n",
    "    \n",
    "    if not all_rpg_enzymes_dict:\n",
    "        print(\"Critical Error: No RPG enzymes are available for digestion. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # 2. Parse FASTA file\n",
    "    ncbi_fasta_sequences = parse_fasta(fasta_file_path)\n",
    "    if not ncbi_fasta_sequences:\n",
    "        print(\"Critical Error: No sequences parsed from FASTA file. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # 3. Load and Filter Excel Data\n",
    "    df_filtered_excel = load_and_filter_excel(excel_file_path, sheet_name='RITA')\n",
    "    if df_filtered_excel.empty:\n",
    "        print(\"Critical Error: No data found or filtered from Excel sheet. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # 4. Merge Excel data with FASTA sequences\n",
    "    df_filtered_excel['Protein_seq'] = df_filtered_excel['NCBI_id'].map(ncbi_fasta_sequences)\n",
    "    \n",
    "    df_analysis = df_filtered_excel.dropna(subset=['Protein_seq']).copy()\n",
    "    num_unmatched = len(df_filtered_excel) - len(df_analysis)\n",
    "    if num_unmatched > 0:\n",
    "        print(f\"Warning: {num_unmatched} rows from Excel could not be matched to FASTA sequences by NCBI_id and were dropped.\")\n",
    "    \n",
    "    if df_analysis.empty:\n",
    "        print(\"Critical Error: No matched protein sequences for analysis. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # 5. Prepare unique proteins for RPG\n",
    "    unique_protein_data = df_analysis[['NCBI_id', 'Protein_seq']].drop_duplicates().set_index('NCBI_id')\n",
    "    \n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    unique_proteins_fasta_path = os.path.join(temp_dir, 'unique_proteins_for_rpg.fasta')\n",
    "\n",
    "    with open(unique_proteins_fasta_path, 'w') as f:\n",
    "        for ncbi_id, row in unique_protein_data.iterrows():\n",
    "            f.write(f\">{ncbi_id}\\n{row['Protein_seq']}\\n\")\n",
    "    print(f\"Unique proteins ({len(unique_protein_data)}) written to temporary FASTA: {unique_proteins_fasta_path}\")\n",
    "\n",
    "    # 6. Run RPG for all available enzymes on unique proteins and collect results\n",
    "    print(\"Initiating RPG digestion for all available enzymes on unique proteins...\")\n",
    "    all_protein_cleavage_results = process_protein_cleavages(\n",
    "        unique_proteins_fasta_path, all_rpg_enzymes_dict, temp_dir\n",
    "    )\n",
    "    print(\"RPG digestion and result collection complete.\")\n",
    "\n",
    "    # 7. Analyze each row of the filtered Excel data and generate enzyme-specific columns\n",
    "    results_for_output = []\n",
    "    print(\"Analyzing tiles and generating final output rows (per enzyme)...\")\n",
    "    \n",
    "    sorted_enzyme_names = sorted(all_rpg_enzymes_dict.keys())\n",
    "\n",
    "    for index, row in df_analysis.iterrows():\n",
    "        ncbi_id = row['NCBI_id']\n",
    "        protein_seq = row['Protein_seq']\n",
    "        \n",
    "        original_tile_seq = row['Aminoacids']\n",
    "        tile_seq = original_tile_seq[1:] if original_tile_seq.startswith('M') else original_tile_seq\n",
    "\n",
    "        output_row = row.to_dict() # Start with existing Excel columns\n",
    "\n",
    "        # Initialize overall protein cleavable status\n",
    "        overall_protein_cleavable = False \n",
    "\n",
    "        protein_cleavage_data_all_enzymes = all_protein_cleavage_results.get(ncbi_id, {})\n",
    "        \n",
    "        for enzyme_name in sorted_enzyme_names: \n",
    "            enzyme_specific_cleavage_data = protein_cleavage_data_all_enzymes.get(enzyme_name, {'cleavage_sites': []})\n",
    "            enzyme_cleavage_sites_list = enzyme_specific_cleavage_data['cleavage_sites']\n",
    "\n",
    "            protein_cleavable_by_enzyme, cleavage_sites_list_for_this_enzyme, tile_cut_by_enzyme, \\\n",
    "            tile_in_x_snip_by_enzyme, distance_nearest_cleave_by_enzyme = \\\n",
    "                get_cleavage_analysis(protein_seq, tile_seq, enzyme_cleavage_sites_list)\n",
    "\n",
    "            # Update overall status if any enzyme cleaves the protein\n",
    "            if protein_cleavable_by_enzyme:\n",
    "                overall_protein_cleavable = True\n",
    "\n",
    "            output_row.update({\n",
    "                f'{enzyme_name}_protein_cleavable': protein_cleavable_by_enzyme,\n",
    "                f'{enzyme_name}_cleavage_sites': \", \".join(map(str, cleavage_sites_list_for_this_enzyme)) if cleavage_sites_list_for_this_enzyme else \"None\",\n",
    "                f'{enzyme_name}_tile_cut': tile_cut_by_enzyme,\n",
    "                f'{enzyme_name}_tile_in_x_snip': tile_in_x_snip_by_enzyme,\n",
    "                f'{enzyme_name}_distance_nearest_cleave': distance_nearest_cleave_by_enzyme\n",
    "            })\n",
    "        \n",
    "        # Add the new summary column after iterating through all enzymes for the protein\n",
    "        output_row['Overall_Protein_Cleavable'] = overall_protein_cleavable # New summary column\n",
    "\n",
    "        results_for_output.append(output_row)\n",
    "\n",
    "    # 8. Create and Save Final Output DataFrame\n",
    "    df_final_output = pd.DataFrame(results_for_output)\n",
    "    \n",
    "    base_columns = [\n",
    "        'tileID', 'log2FoldChange', 'padj', 'type', 'sig', 'Virus', 'NCBI_id', 'Uniprot_id', 'Gene_name', 'Aminoacids', 'Protein_seq',\n",
    "        'Overall_Protein_Cleavable' # Add the new summary column here\n",
    "    ]\n",
    "    \n",
    "    enzyme_specific_output_cols = []\n",
    "    for enzyme_name in sorted_enzyme_names:\n",
    "        enzyme_specific_output_cols.extend([\n",
    "            f'{enzyme_name}_protein_cleavable',\n",
    "            f'{enzyme_name}_cleavage_sites',\n",
    "            f'{enzyme_name}_tile_cut',\n",
    "            f'{enzyme_name}_tile_in_x_snip',\n",
    "            f'{enzyme_name}_distance_nearest_cleave'\n",
    "        ])\n",
    "\n",
    "    final_columns = base_columns + enzyme_specific_output_cols\n",
    "\n",
    "    for col in final_columns:\n",
    "        if col not in df_final_output.columns:\n",
    "            df_final_output[col] = 'None' \n",
    "\n",
    "    df_final_output = df_final_output[final_columns]\n",
    "    df_final_output = df_final_output.fillna('None') \n",
    "\n",
    "    try:\n",
    "        df_final_output.to_csv(output_csv_path, index=False)\n",
    "        print(f\"\\nPipeline complete. Results saved to {output_csv_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving final output CSV: {e}\")\n",
    "    finally:\n",
    "        try:\n",
    "            for f in os.listdir(temp_dir):\n",
    "                os.remove(os.path.join(temp_dir, f))\n",
    "            os.rmdir(temp_dir)\n",
    "            print(f\"Cleaned up temporary directory: {temp_dir}\")\n",
    "        except OSError as e:\n",
    "            print(f\"Error cleaning up temporary directory {temp_dir}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fasta_input = 'data/all_virus_proteins.fasta'\n",
    "    excel_input = 'data/RITA_and_ABT_pos_selection_screens.xlsx'\n",
    "    output_final_csv = 'results/RITA_virus_cleavage_analysis.csv' \n",
    "    \n",
    "    main_pipeline(fasta_input, excel_input, output_final_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rpg_analysis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
